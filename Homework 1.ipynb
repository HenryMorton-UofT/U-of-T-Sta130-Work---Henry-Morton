{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c0e8f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccf78d49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 391 rows and 11 columns.\n"
     ]
    }
   ],
   "source": [
    "dimensions = df.shape\n",
    "print(f\"The dataset has {dimensions[0]} rows and {dimensions[1]} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3458659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df.describe()\n",
    "print(summary_stats)\n",
    "species_counts = df['species'].value_counts()\n",
    "print(species_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea118e07",
   "metadata": {},
   "source": [
    "df.shape will describe the total number of columns and rows. However, df.describe only provides summary statistics for numeric columns. Therefore, columns which have categorical data for example will be ignored by df.describe. If there are missing values, then the “count” value for each numeric column (whichrepresents the number of non-missing values.) will be less than the total number of rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2356c2b",
   "metadata": {},
   "source": [
    "The difference between an attribute and method is in what they do. An attribute simply describes a static value of state, and doesn't perform any actions/computaions. An example of this is df.columns simply provides column names. A method, on the other hand, needs to perform an action or computation. For example, df.mean() will compute the mean of any numeric column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46286bd9",
   "metadata": {},
   "source": [
    "1. Count: The count is the number of non-null entries for each variable/column/row.\n",
    "2. Mean: The mean is the average of the entries for each variable/column/row.\n",
    "3. Standard Deviation: The standard deviation is a measure of dispersion of values around the mean of a variable/column/row.\n",
    "4: Min: The minimum function returns the smallest value within the variable/column\n",
    "5: 25%. This gives the first quartile, which means the value at which 25% of the data in the column/variable is smaller than.\n",
    "6 50%. This gives the median, which means the value at which 50% of the data in the column/variable is smaller than.\n",
    "7. 75%.This gives the third quartile, which means the value at which 785% of the data in the column/variable is smaller than.\n",
    "8: Max: The maximum function returns the largest value within the variable/column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd288a",
   "metadata": {},
   "source": [
    "An example of a case where I would want to use df.dropna() is if I made a survery, and there was a common trend of repsondents skipping the same questions. Therefore, I would use df.dropna() to drop these rows with many missing values. An example of a case where I would want to use del df['col'] is when the inverse is the case, some columns have lots of missing data. If I wanted to use both, it would be wise to use del df['col'] as removing columns can decrease the size of the dataset, thus speeding up subsequent operations. Additionally, dropping columns first insures that only rows missing critical data are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca1db9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore cleaning:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39minfo())\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Remove columns with any missing values\u001b[39;00m\n\u001b[1;32m      4\u001b[0m df_cleaned_columns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Before cleaning:\")\n",
    "print(df.info())\n",
    "# Remove columns with any missing values\n",
    "df_cleaned_columns = df.dropna(axis=1)\n",
    "\n",
    "# Remove rows with any missing values\n",
    "df_cleaned = df_cleaned_columns.dropna()\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(df_cleaned.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed0119",
   "metadata": {},
   "source": [
    "The justification is that we remove all columns with missing values, then all rows with missing values. Thus, all missing values will be deleted.This can be shown in the difference in memory usage in the before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2d09ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "class            0\n",
       "who              0\n",
       "adult_male       0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alive            0\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2 = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df2 = pd.read_csv(url2)\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db225a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deck</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>12.0</td>\n",
       "      <td>44.833333</td>\n",
       "      <td>20.171237</td>\n",
       "      <td>4.00</td>\n",
       "      <td>34.75</td>\n",
       "      <td>44.0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>45.0</td>\n",
       "      <td>34.955556</td>\n",
       "      <td>15.491868</td>\n",
       "      <td>11.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>51.0</td>\n",
       "      <td>36.086667</td>\n",
       "      <td>14.379481</td>\n",
       "      <td>0.92</td>\n",
       "      <td>25.50</td>\n",
       "      <td>36.0</td>\n",
       "      <td>47.50</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>31.0</td>\n",
       "      <td>39.032258</td>\n",
       "      <td>14.460253</td>\n",
       "      <td>16.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>37.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>30.0</td>\n",
       "      <td>38.116667</td>\n",
       "      <td>12.590146</td>\n",
       "      <td>6.00</td>\n",
       "      <td>30.50</td>\n",
       "      <td>39.0</td>\n",
       "      <td>47.00</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>11.0</td>\n",
       "      <td>19.954545</td>\n",
       "      <td>15.182975</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.50</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>13.744696</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count       mean        std    min    25%   50%    75%   max\n",
       "deck                                                              \n",
       "A      12.0  44.833333  20.171237   4.00  34.75  44.0  56.00  80.0\n",
       "B      45.0  34.955556  15.491868  11.00  24.00  33.0  44.00  70.0\n",
       "C      51.0  36.086667  14.379481   0.92  25.50  36.0  47.50  64.0\n",
       "D      31.0  39.032258  14.460253  16.00  25.00  37.0  50.00  63.0\n",
       "E      30.0  38.116667  12.590146   6.00  30.50  39.0  47.00  65.0\n",
       "F      11.0  19.954545  15.182975   1.00   3.50  24.0  31.50  42.0\n",
       "G       4.0  14.750000  13.744696   2.00   3.50  14.0  25.25  29.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(\"deck\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a44108c",
   "metadata": {},
   "source": [
    "df.describe() shows the count of non-missing values for col2 and col3 across the entire DataFrame.\n",
    "df.groupby(\"col1\")(\"col2\".describe() shows the count of non-missing values for col2 within each group of col1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234d6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "8.3.A: For this error, asking the chatbot fixes it straight away as it instantly informs me I haven't imported Pandas. It was harder to find a solution to my problem on Google.\n",
    "    B: Once again the chatbot spotted this error immediately. Google was less efficient.\n",
    "    C: Once again the chatbot noticed the error first try. It was harder to find a solution to my problem on Google.\n",
    "    D: The chatbot was onto this one in an instant too.It was harder to find a solution to my problem on Google..\n",
    "    E: The chatbot exposed this error prompotly. Google was less efficient.\n",
    "    F: Again the chatbot saved me. Google was less efficient.\n",
    "    G:Neither the chatbot or google could help me in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839ab58",
   "metadata": {},
   "source": [
    "Question 9: Yes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3afa5967",
   "metadata": {},
   "source": [
    "Chatbot Summaries: Copilot was used as the main chatbot, however, due to character limits and prompt limits,\n",
    "ChatGPT was used to create multiple summaries: \n",
    "#1:In this conversation, the user seeks to understand their dataset from Animal Crossing, starting with an inquiry\n",
    "about its size and structure. The assistant explains how to check the dataset's dimensions using Python and \n",
    "provides examples of common analysis methods (df.describe() and df['column'].value_counts()).\n",
    "Further, the user asks about discrepancies in results from df.shape and df.describe() concerning missing values \n",
    "and non-numeric variables. The assistant clarifies that df.describe() only analyzes numeric columns and excludes \n",
    "missing values, while df.shape includes all rows and columns. Finally, the user asks about the difference between \n",
    "an \"attribute\" (like df.shape) and a \"method\" (like df.describe()), and the assistant explains the distinction \n",
    "between attributes as properties of objects and methods as functions performing actions on the data.\n",
    "#2 The conversation covered the following points:\n",
    "Definitions of summary statistics (count, mean, std, min, 25%, 50%, 75%, max) provided by df.describe().\n",
    "Clarification that count in df.describe() refers to non-null entries in each column.\n",
    "Comparison of when to use df.dropna() vs. del df['col'] for handling missing data, along with examples.\n",
    "Discussion on why removing columns with del df['col'] before applying df.dropna() can be more efficient.\n",
    "An example of using df.dropna() to remove rows or columns with missing values, along with parameters to adjust its behavior.\n",
    "#3 In this conversation, you discussed cleaning a dataset using Python and pandas. Here's a summary:\n",
    "Loading the Data: You imported the dataset from a URL into a pandas DataFrame.\n",
    "Initial Steps: You were guided to preview the data, check for missing values, and get summary statistics.\n",
    "Handling Missing Values:\n",
    "You wanted to remove missing values but initially suggested using del df['col'], which is for deleting columns, not handling missing data.\n",
    "The correct method to remove missing values is df.dropna() for dropping rows with missing values.\n",
    "Implementation:\n",
    "You provided code to load the dataset, check the data before and after cleaning, and remove rows with missing values.\n",
    "You also asked how to identify columns with many missing values, and the solution involved using df.isnull().sum() and setting a threshold for missing values.\n",
    "Issue Encountered:\n",
    "The code didn't produce any output in Jupyter Hub, which was resolved by ensuring proper use of print() statements and checking the execution of each cell.\n",
    "#4 In this conversation, you encountered an error stating that df was not defined. Here’s a summary of the troubleshooting and resolution steps:\n",
    "Error Diagnosis:\n",
    "The error \"df is not defined\" usually occurs if the df variable is used before it’s defined, or due to syntax errors or scope issues.\n",
    "Possible Solutions:\n",
    "Variable Definition: Ensure df is defined before use.\n",
    "Missing Import: Verify that pandas is imported.\n",
    "Scope Issues: If df is inside a function, it must be returned or declared global.\n",
    "Corrected Code:\n",
    "You provided code to load the dataset, check for missing values, and display DataFrame info. Corrections were made for syntax errors, such as adding new lines between commands.\n",
    "Code Execution:\n",
    "The corrected code successfully loaded the dataset, checked for missing values, and identified columns with missing values.\n",
    "Further Actions:\n",
    "You decided to remove all columns with missing values first and then rows with missing values. The updated code was provided to show the DataFrame before and after cleaning, ensuring clarity in the data cleaning process.\n",
    "If you need more help or adjustments, just let me know!\n",
    "#5: In this conversation, you explored the following aspects of analyzing a dataset using Python and pandas:\n",
    "Basic Analysis Code:\n",
    "You discussed the initial steps for analyzing the Titanic dataset, including loading the data, displaying the first few rows, getting summary statistics, and checking for missing values.\n",
    "Group-by Operation:\n",
    "You asked about df.groupby(\"col1\")[\"col2\"].describe(), which groups the DataFrame by values in col1 and calculates descriptive statistics for col2 within each group. This includes counts, means, standard deviations, and other statistical measures for each group.\n",
    "Differences in Count Values:\n",
    "You questioned why df.describe() and df.groupby(\"col1\")[\"col2\"].describe() show different counts, especially in the context of missing values.\n",
    "df.describe(): Provides summary statistics for each numerical column in the entire DataFrame, showing the count of non-missing values for each column.\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): Provides statistics for col2 within each group defined by col1, showing counts specific to each group.\n",
    "Illustration with Example:\n",
    "An example DataFrame was used to demonstrate the difference between overall summary statistics and group-specific statistics, highlighting how missing values are handled differently in each context.\n",
    "If you have more questions or need further explanations, feel free to ask!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
